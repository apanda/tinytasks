\section{Architecting for Tiny Tasks}
\label{sec:architecture}

% Argue that we need a new architecture
While existing frameworks can benefit from the use of smaller tasks (as shown
in Figure~\ref{fig:sparkskew}), supporting tiny tasks for all jobs in a large cluster
requires addressing numerous challenges.
A cluster supporting tiny tasks must provide low task launch overheads and use
a highly scalable scheduler that can
handle hundreds of thousands of scheduling decisions per second. % and
%launch tasks with low overhead.
Tiny tasks operate on
small blocks of data, and hence require a scalable file system. To ensure that
tasks can complete quickly, we propose giving the framework more control
over I/O. % so that, for example, a task's data is already in-memory when the
%task is launched.
Finally, ensuring
that all jobs can be broken into tiny tasks requires some improvements
to the programming model; e.g., support for framework-managed temporary storage.
In this section, we discuss a preliminary architecture to address
each of these challenges and the lower bound that each challenge places
on response time; we aim for tasks that are as small as possible.
We find that tasks that complete in hundreds of milliseconds
are practical in the short-term, and that we can drive task launch overhead
down to further reduce task runtime in the future.

\subsection{Execution Model}
We propose a task execution model that supports data-parallel computations
expressed using a variety of popular programming frameworks (e.g.,
MapReduce~\cite{dean2004mapreduce}, Spark~\cite{zaharia2010spark},
DryadLINQ~\cite{yu2008dryadlinq}).
A job is composed of a number of tasks, each representing an atomic
and idempotent unit of execution. A task consists of a set of named inputs
and code that operates on these inputs, and each task runs on a single machine.
We assume a cooperative scheduling model; i.e., tasks explicitly release
resources on completion (in contrast to preemptive models, discussed in
\S\ref{sec:preemption}).

%We assume that the framework is used to support data-parallel programs whose input
%data reside on disk, and the workload is I/O bound.

%To allow tasks to complete quickly, we propose operating on data blocks of
%at most $8$MB.
%Previous work has shown that $8$MB random disk reads achieve
%approximately $88$\% of the bandwidth of sequential reads, and smaller reads would
%cause significant performance degradation due to disk seeks~\cite{nightingale2012flat}.
%Assuming $100$MB/s disk throughput in a fully pipelined execution framework, each task
%can execute up roughly $100$ms to process the $8$MB input.

%Although frameworks such as Spark are significantly better
%than traditional frameworks such as Hadoop in handling smaller tasks,
%Figure~\ref{fig:sparkskew} shows the need for a new execution framework
%to truly support tiny tasks at $100$ms range.

% While newer data-parallel frameworks like Spark can support tasks of finer-granularity,
% Figure~\ref{fig:sparkskew} shows that even in newer frameworks like Spark,
% benefit from the use of
% smaller tasks, Figure~\ref{fig:sparkskew}
% shows the need for a new task execution framework to truly support tiny tasks across a wide
% variety of jobs.

%Supporting tiny tasks requires a highly scalable scheduler that can handle hundreds
%of thousands of scheduling decisions per second. We also argue that efficiently using
%tiny tasks requires task launch overheads be reduced to $1$ms or less.
%Efficiently utilizing CPU and I/O resources with low task runtimes requires
%a pipelined task execution model where the execution framework manages I/O
%requests for input, output and intermediate data. We use a cooperative
%scheduling model, i.e., resources are reassigned after tasks explicitly release
%them on finishing. Task runtimes are limited by limiting input size and
%appropriate modifications to programming frameworks. Section~\ref{sec:alternate}
%compares our design to other alternatives.


% The task execution framework
% pre-fetches inputs before running a task and is responsible for saving
% outputs to disk or transferring them over the network.

\subsection{Scalable Storage Systems}

In the short term, we expect the time needed to read input data to be the
limiting factor in driving down task durations.
Previous work has shown that 8MB random disk reads can achieve approximately 88\%
of the throughput of sequential reads, and that smaller
random reads cause significant performance degradation due to disk seeks~\cite{nightingale2012flat}. Thus, as long as input data is stored on disk, we
require that tasks read at least 8MB of input data. Data-parallel
workloads are commonly I/O bound, so we expect task runtime to be dominated
by time taken to read input data; thus,
assuming 100MB/s disk throughput, 8MB input data sizes should result in task durations
of hundreds of milliseconds.

Using small data blocks requires a move away from traditional distributed file systems like
HDFS, where scalability limitations prevent the use of small blocks.
While HDFS does allow tasks to read only part of a block, having multiple tiny tasks
that operate on the same file block limits parallelism.
Recent work on distributed filesystems, e.g., Flat Data Center
Storage (FDS)~\cite{nightingale2012flat}, addresses these scalability concerns by
distributing metadata across multiple servers.
%While FDS adequately addresses scalability concerns, but a framework built for
%tiny tasks can improve performance by using a closely integrating the file
%system and the scheduler, as discussed in \S\ref{sec:pipeline}.
As discussed in \S\ref{sec:pipeline}, a framework built for tiny tasks can
improve on FDS performance by more closely integrating the file system and
the task scheduler.
\eat{
The effective use of tiny tasks also requires close coordination between the file
system, the scheduler, and the caching layer.
In particular, locality based scheduling, pipelined data access, caching blocks in
memory, and effective coordination of network traffic are closely linked, and
must be considered holistically. We propose building a globally aware, distributed
component that accounts for these factors.
%, and provides additional information to
%both the scheduler, and the filesystem.
}


\subsection{Low-Latency Scheduling}
\label{sec:sched}
Supporting tiny tasks requires a low-latency, high throughput task scheduler.
Handling $100$ms tasks in a cluster with $160,000$ cores
(e.g., 10,000 16-core machines),
requires a scheduler that can, on average, make $1.6$ million scheduling
decisions per second.
Today's centralized schedulers have well-known scalability
limits~\cite{wilkes2013omega} that
hinder their ability to support tiny tasks in a large cluster.
Engineering improvements such as compressing task descriptions,
avoiding sending the same task description to the same machine multiple
times, and using more efficient networking have helped some
centralized schedulers
provide higher throughput~\cite{zaharia2012meetup}.
However, handling large clusters and very
short tasks may require a decentralized scheduler design.
Recently proposed distributed schedulers (e.g., Sparrow~\cite{ousterhoutbatch})
can scale well beyond millions of decisions per second while providing near-optimal
response times.
Our proposed system relies on the use of such distributed schedulers.
%Since a job completes only when all of its tasks complete, we also plan to
%explore techniques like gang scheduling~\cite{feitelson1992gang} to minimize
%overall job completion time.

In addition to providing high throughput scheduling decisions, a framework for
tiny tasks must also reduce the overhead for launching individual tasks.
%especially in the case of cooperative scheduling.
%Consider for an average task length of $100$ms, in order to achieve 99\% utilization,
%task launch overhead should be less than $1$ms.
%Popular frameworks like Hadoop MapReduce
%have task launch overheads of many seconds, largely due to the use of
%heartbeat messages to communicate scheduling decisions and the need to launch new
%processes for each task.
Popular frameworks like Hadoop MapReduce have task launch overheads of many
seconds, due to a variety of factors including the need to launch a new
JVM for each task; newer frameworks like Spark~\cite{zaharia2010spark} reduce
the overhead to $5$ms.
To support tasks that complete in hundreds of milliseconds, we argue for
reducing task launch overhead even further to $1$ms so that launch overhead
constitutes at most 1\% of task runtime.
By maintaining an active threadpool for task execution on each worker node
and caching binaries, task launch overhead can be reduced to the time to
make
 a remote procedure
call to the slave machine to launch the task. Today's datacenter networks
easily allow a RPC to complete within $1$ms. In fact, recent work showed that
$10\mu$s RPCs are possible in the short term~\cite{low-latency}; thus,
with careful engineering, we believe task launch overheads of $50\mu$s are
attainable. $50\mu$s task launch overheads would enable even smaller tasks
that could read data from in-memory or from flash storage in order to complete
in milliseconds.
\eat{
so that launch overhead constitutes
less than 1\% of task runtime.
A framework for tiny tasks
If the framework maintains an active threadpool for task execution on each worker,
task launching should be essentially a remote procedure call.
With careful engineering,
it is attainable to reduce the overhead to a level much lower than the
required $1$ms, as it has been shown that $5\mu$s-$10\mu$s RPCs are possible
in the short term~\cite{low-latency}.
}
%\subsection{Pipelined Execution}
\subsection{Framework-Controlled I/O}
\label{sec:pipeline}
Using tiny tasks fundamentally changes the resource footprint of tasks,
giving the framework more control to optimize I/O.
Today's large tasks accumulate a large amount of output data in memory.
Often this output data will exceed available memory and spill onto disk,
leading to poor MapReduce performance~\cite{lipcon2012optimizing}.
Tiny tasks fundamentally change the task resource footprint: since tasks
run for a shorter period of time, they generate less output data and thus use
less memory. The framework can explicitly control the remaining memory, caching
the most important data and storing remaining data on disk or on a different
machine.
%For example, output data can be written to disk in the background, while
%more tasks are executing, alleviating performance problems caused by spilling
%data to disk during task execution.
For MapReduce-style jobs, the framework could store the map
outputs that will be used for the first set of reduce tasks in memory, and store
remaining outputs on disk. While the first set of tiny reduce tasks are running,
the framework can pipeline reading data for the next set of tasks.
This approach considers file system scheduling, network scheduling, task scheduling,
and caching holistically. The benefits of a more holistic approach to
scheduling have been illustrated in more restricted settings (e.g., in the
context of network scheduling~\cite{chowdhury2012coflow,chowdhury2011managing}),
but validating our broader approach remains for future work.
\eat{
We propose further optimizing I/O by breaking each task into three phases, and
scheduling each phase separately. Current task execution involves fetching data
(typically from disk), processing this data, and storing the output (sometimes
by sending the output over the network). By breaking apart these phases and scheduling each separately,
the framework can optimize resource usage: the framework need not guess when
a task will need to use the disk, for example, and can opportunistically
read input data for future tasks from disk or over the network when resources are
idle. This approach assumes that considering file system scheduling, data
caching, network
scheduling, and task scheduling holistically will improve performance.
The benefits of a more holistic approach to scheduling have been illustrated in
restricted
settings (e.g., in the context of network scheduling~\cite{chowdhury2012coflow,chowdhury2011managing}), but validating our more radical approach is the subject of ongoing work.
    }
 \eat{
The framework can store the most frequently used output data in memory, and flush
remaining data to disk.

%To optimize for short tasks, we propose pipelining the phases of task execution.
%Current task execution involves a task fetching data from the disk, or over the network,
%processing this data, and storing the output either on memory or on disk. We observe
%that these three steps are independent phases. We propose pipelining these phases such that one task's
%input is fetched while another task is running, thus more fully utilizing both
%the CPU and the I/O bus.
To optimize for tiny tasks, we propose giving the framework more control over I/O.
Current task execution involves a task fetching data (typically from disk), processing
this data, and storing the output either on memory or on disk.

decouple stages of a task
over tasks life time, using many types of resources. instead of traditional thing,
assign each independently, leads to pipelining
doing this reduces the efficiency loss from having so many small tasks

by tightly integrating the task scheduler and the file system.

To improve the efficiency and response time of small tasks, we propose giving
the framework more control over I/O by tightly integrating the scheduler
and the file system. Traditionally, task execution involves fetching data (often
from disk), processing this data, and outputting the data (by storing data in
memory or on disk, or by sending the data over the network). We propose scheduling
each of these three phases independently. This approach allows the scheduler to
keep disks, CPU, and network resources all highly utilized, without needing to guess
when a task will need to use each resource.

A scheduler for tiny tasks can improve efficiency and utilization by tightly
controlling I/O.
% More control over I/O
Tiny tasks fundamentally change the resource footprint of tasks, giving the framework
more control over I/O. We propose leveraging this additional control by tightly
integrating the task scheduler and the distributed file system.
Today's large tasks accumulate a large amount of output data in memory.
Often this output data will exceed available memory,
and will spill onto a disk, leading to poor MapReduce
performance~\cite{lipcon2012optimizing}. Tiny tasks fundamentally change the
resource footprint of tasks: since tasks run for a shorter period of time,
they generate less output data and thus use less memory. When a tiny task completes,
it explicitly gives control of its output data to the framework.
The framework can choose to cache the most important and most frequently-accessed
output data, and store the remaining data on disk or move it to a different machine.

% Why this control is useful

% Efficiency improvement0
% Memory foot print different --> framework can decide what to do with data (and
% no problems with data spilling to disk)
% further benefits. We propose further optimizing by pipelining, considering these
% things holsitically, understanding benefit is subject of future work.
Data written to disk can be written in the background, while more tasks for the
job are run, alleviating the performance problems caused by spilling data to disk
during task execution.


The framework can
explicitly control the remaining memory, choosing to cache the most important
and most frequently-accessed output data, and store the remaining data on disk
or on a different machine. Data written to disk can be written in the
background, while more tasks for the job are run, alleviating the performance
problems caused by spilling data to disk during task execution.
Shifting control of I/O entirely to the framework also allows for
powerful optimizations.  For a MapReduce-style job, for instance, the
framework could store the map outputs that will be used for the first set of
tiny reduce tasks in memory, and store the remaining outputs on disk. While
the first set of tiny reduce tasks are running, the framework can pipeline
reading data for the next set of tasks.  Giving frameworks better control over
I/O has been shown
to greatly improve network utilization and performance in
clusters~\cite{chowdhury2011managing, chowdhury2012coflow}.


Using tiny tasks enables the framework to improve efficiency and utilization
by optimizing I/O. Tiny tasks fundamentally change the resource footprint of
tasks, and give the framework more choice in when to transfer data

Using tiny tasks requires providing the framework with additional control to optimize I/O.
%Pipelining is particularly powerful when combined with small tasks.
Today's large tasks accumulate a large amount of output data in memory.
Often this output data will exceed available memory,
and will spill onto a disk, leading to poor MapReduce
performance~\cite{lipcon2012optimizing}. Tiny tasks fundamentally change the
resource footprint of tasks: since tasks run for a shorter period of time,
they generate less output data and thus use less memory. The framework can
explicitly control the remaining memory, choosing to cache the most important
and most frequently-accessed output data, and store the remaining data on disk
or on a different machine. Data written to disk can be written in the
background, while more tasks for the job are run, alleviating the performance
problems caused by spilling data to disk during task execution.
Shifting control of I/O entirely to the framework also allows for
powerful optimizations.  For a MapReduce-style job, for instance, the
framework could store the map outputs that will be used for the first set of
tiny reduce tasks in memory, and store the remaining outputs on disk. While
the first set of tiny reduce tasks are running, the framework can pipeline
reading data for the next set of tasks.  Giving frameworks better control over
I/O has been shown
to greatly improve network utilization and performance in
clusters~\cite{chowdhury2011managing, chowdhury2012coflow}.
}
\subsection{Programming model}
\label{sec:prog}
Most tasks in a data parallel framework can be split into tiny tasks by
reducing the input size; however, some types of tasks cannot easily be
parallelized. Parallelizing all jobs is the most significant challenge
in realizing tiny tasks.
Consider, for example, reduce tasks in a MapReduce job. In the limit,
one reduce task can be launched to handle each key. However, if all
values map to the same key, that key cannot easily be split into multiple
tasks.
%granularity of a reduce task
%is to process a single key.
%When a single key contains a large number of values, the reduce task might
%violate the tiny task constraint.
When the reduce function is associative and commutative, such tasks can be parallelized using techniques like map-side combiners or aggregation trees.
These techniques are already used by existing frameworks \cite{yu2008dryadlinq}, and will allow most jobs to be split into tiny tasks.
%Data parallel frameworks like Dryad~\cite{yu2008dryadlinq} use aggregation trees to solve
%similar problems by progressively combining inputs from multiple tasks;
%aggregation trees will allow parallelizing tasks where the function
%is commutative and associative.

%While splitting most tasks in a dataparallel framework by reducing input size
%is straight forward, splitting certain tasks might incur a higher overhead
%than the corresponding improvements.

% Some data parallel frameworks like Dryad~\cite{yu2008dryadlinq} use aggregation
% trees to solve similar problems by progressively combining outputs from
% multiple tasks. Leveraging aggregation trees will allow a tiny tasks framework
% to reduce task lengths for a wider variety of tasks. For instance, consider a
% job that groups values by some criterion, and calculates the mean for each group.
% In this case, aggregation trees provide a mechanism for dividing an individual group
% across multiple tasks.

Despite the use of aggregation trees, some tasks may remain
difficult to divide into tiny tasks.
%For example, tasks that are not associative and
%commutative do not lend themselves to the use of aggregation trees.
%In our example above, a more complicated operation might not lend itself to being
%simplified using an aggregation tree.
To split these tasks, we propose providing a framework-managed
temporary state store that can be used to communicate and share data between a
job's tiny tasks.
For instance, to implement a job that computes distinct values, we could store hashes of all values seen so far in the state store.
%Such a store could be used to implement a job that computes
%distinct values in a file, for instance, by storing hashes of all values
%seen so far.
We envision that this store would have a key-value interface and provide strong consistency guarantees.

Inevitably, some tasks will be impractical to split, despite these tools.
To accommodate such
tasks, we plan on allowing some large tasks to run on the cluster. We expect
that if a small percentage of tasks remain large, they can be run on the same
infrastructure as tiny tasks without impacting the performance of remaining tasks.
Exploring the impact of such sharing is the subject of ongoing research.
%These tasks
%may need to run on a small part of the cluster reserved for large tasks.
%Alternately, we expect that if a small percentage of tasks remain large, they
%can be run on the same infrastructure as tiny tasks without impacting the
%performance of remaining tasks. Exploring the effects of such sharing is
%the subject of ongoing research.
