\section{Introduction}
Today's systems accept work in discrete units: networks process flows of data
between two endpoints, operating systems execute individual applications, and
data centers process data in individual jobs.  In the context of networks and
operating systems, system designers have found that indivisible \st{finite} units of work to be
inconvenient: indivisible \st{finite} units of work limit utilization and load balancing,
and complicate fair sharing.  Instead, networks divide large flows into small
packets, and operating systems run applications in pre-emptable units of a 
few milliseconds, thus approximating a fluid flow.  This paper argues for
bringing this fluid flow model \panda{I am not entirely sure we should call this
the ``fluid-flow'' model, partly because we are still arguing for quantization, not
infinitely small units of work} to the data center by breaking jobs up into
millions of ``tiny tasks'' that each complete in hundreds of milliseconds.

Tiny tasks solve three major problems in today's datacenters:
\begin{itemize}
\item \textbf{Running batch jobs alongside interactive ones}: Running interactive
jobs is difficult in today's datacenters because long-running, batch jobs may be
using the resources needed by an interactive job. Bursts of interactive jobs
cannot be serviced quickly, because they must wait for batch jobs to complete.
\panda{We should phrase this in terms of tasks not jobs. In particular if a job has
10 tasks that must run on the same machine, you can fit a task from an interactive job
in there in between the two. The real problem is that the tasks themselves are pretty
long.}
This problem frustrates data analysts trying to run real-time queries, and makes
running user-facing services alongside batch services impossible. Breaking large
jobs into millions of tiny tasks, each with runtime similar to the runtime for a
task in a user-facing service, eliminates this problem.
\item \textbf{Data Skew}: Data skew affects jobs in two ways: first, some tasks
may be processing far more data than other tasks, causing them to take much
longer; and second, congested network links due to one or more large jobs using
the same link can slow down other jobs reading data over the same link. Dividing
jobs into millions of tiny tasks dramatically improves load balancing to eliminate
this problem.
\item \textbf{Outliers}: Today's frameworks are plagued by outliers: tasks that
take as much as 10 or 100x longer than other tasks in the same job due to
resource contention at the machine or on the network or data skew.  If all tasks in a job execute in parallel, the job takes 10 or 100x longer than it would
have without the outlier, prompting a flurry of work on mitigating the outlier
problem ~\cite{blah,blah,blah}. On the other hand, if the job is broken into millions of tiny tasks (only a subset of which execute at any given time), a machine
that runs an outlier task will simply run fewer total tasks, rather than
stalling the completion time for the entire job.
\item \textbf{Misc Others that we'll probably eliminate:} Fragmentation (solves
lots of YARN's problems)
\end{itemize}

Breaking jobs into tiny units of work requires a re-architecting of today's frameworks.  We argue that these challenges are not insurmountable, and in fact, many
have been solved by prior work:
\begin{itemize}
\item Task launch overhead: start JVM for MapReduce. Spark doesn't do this.
\item Scheduling: sparrow
\item Small file system blocks: FDS
\end{itemize}

Contributions of this paper:
\begin{itemize}
\item Quantify benefits of tiny taks (5x speedup from outlier problem, 2x speedup
from data skew problem, ?? from batch/interactive)
\item Outline system architecture
\item Quantify how low we can go (100ms?)
\end{itemize}

\begin{comment}
Today's datacenters run increasingly diverse workloads. A decade ago, compute
clusters were designed for batch workloads: a typical job took hours to complete.
As users migrated large amounts of data to these clusters, they demanded ever
faster access to this data, spurring low-latency frameworks (e.g., Dremel, Spark,
Shark, Impala) that stripe work across thousands of machines or store data in
memory in order to complete jobs in seconds. While data analysts and user-facing
services rely on these low-latency frameworks, clusters continue to run
long-running, batch jobs (e.g., indexing the web), leading to a diverse mix of
job runtimes.  Workload studies from Facebook, Microsoft, Yahoo!, and Google
corroborate this claim, finding that job completion times range from seconds to days.
\end{comment}
