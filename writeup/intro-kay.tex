\section{Introduction}
Cluster computing has become widespread, leading to a proliferation of
research on improving performance for data-parallel computations.
Researchers have attempted
to tackle numerous problems that arise in this setting
including
unfairness~\cite{ananthanarayanan2013effective,hindman2011mesos,isard2009quincy,zaharia2008improving},
stragglers~\cite{ananthanarayanan2013effective,ananthanarayanan2010reining}, and skew~\cite{ananthanarayanan2011scarlett,gufler2012load,kwon2012skewtune}.
Reducing task granularity alleviates all of these problems, yet surprisingly has
not been explored in this context.
%Prior efforts use a variety of techniques but surprisingly overlook a single
%variable: task granularity.
%While these efforts use a variety of techniques, we argue that a single aspect
% asset approach technique aspect variable facet
%can address all of these challenges
%by improving
%fairness~\cite{zaharia2008improving,hindman2011mesos},
%supporting preemption~\cite{ananthanarayanan2012true,isard2009quincy},
%mitigating stragglers~\cite{ananthanarayanan2010reining,ananthanarayanan2012why},
%and reducing skew~\cite{ananthanarayanan2011scarlett,kwon2012skewtune,gufler2012load}.
%These efforts have significantly improved performance and efficiency.
%We argue that a single variable affects all of these challenges: the
%granularity of tasks.
%We argue that a single variable underlies all of these
%We argue that a single variable affects all of these challenges: the granularity
%of tasks.
%We argue that task granularity affects all of these challenges.
%Surprisingly,
%to the best of our knowledge, no one has explored the effect of lowering
%task granularity on data-parallel computations.
% on these problems.
%This paper argues that a single variable affects all of these scheduling
%challenges
%Yet, they have surprisingly not explored a single variable that affects all
%of the
%aforementioned challenges: the granularity of tasks.
%Reducing task granularity addresses all of these problems.
Historically, task launch overheads have prevented the use of smaller tasks,
but recent improvements in distributed file systems and
scheduling eliminate scaling bottlenecks.
%prohibited the use of sub-second
%tasks; however, recent advances in scheduler and
Thus, we argue for
breaking all jobs into \emph{tiny tasks}, which offers the following benefits:
%alleviates or eliminates
%the following problems:
%solves many problems in
%current data-parallel frameworks:

\eat{
Computer systems schedule and manage a variety of types of work:
%Today's systems accept work in discrete units:
networks process flows of data
between two endpoints, operating systems execute individual applications, and
data centers process data in individual jobs.  In the context of networks and
operating systems, system designers have found that large, indivisible units of work limit utilization and load balancing,
and complicate fair sharing.  Instead, networks divide large flows into small
packets, and operating systems run applications in pre-emptable units of a
few milliseconds.  This paper argues for
applying a similar model to data centers by breaking all jobs into
``tiny tasks,'' each of which runs for a few hundred
milliseconds. We argue that even batch jobs that take hours to complete
should be broken into tiny units of work that each complete quickly.

Tiny tasks solve two major problems in current data-parallel frameworks:
%Decreased task runtimes solve two major problems in today's datacenters:
}
%\vspace{4pt}
\noindent\textbf{Batch and interactive sharing:}
Current clusters are required to tradeoff utilization and responsiveness.
If a cluster is highly utilized, an interactive job may need to wait for long-running
batch tasks to complete before it can be serviced; reserving slots for
interactive jobs avoids this problem but results in lower
utilization.
%In a highly utilized cluster, if a high priority interactive job arrives,
%the job may
%need to wait for long-running, batch tasks to complete before being launched, sacrificing responsiveness.
%On the other end of the spectrum, a cluster can maintain a reserved
%set of machines for high priority jobs, which provides responsiveness at
%the expense of utilization.
%a high priority job in a highly utilized cluster might
%need to wait for long-running tasks to complete before being run.
Tiny tasks allow a cluster to be \emph{both} responsive and highly utilized, since small tasks ensure frequent opportunities for new,
interactive jobs to be launched.

%\vspace{4pt}
\noindent\textbf{Straggler mitigation:}
Prior work has shown that job runtimes are largely determined by
stragglers: tasks that take much longer to complete than other tasks in the
job.
%This problem has led to a wide variety of techniques to ensure that
%work is evenly balanced across tasks~\cite{gufler2012load,kwon12skewtune}, and to
%speculatively launch
%redundant tasks when a task appears to be running on a slow machine~\cite{dean2004mapreduce,zaharia2008improving,ananthanarayanan2010reining}.
Tiny tasks alleviate the straggler problem because work is allocated to
machines at a fine granularity, so work can be evenly spread
over available resources, and slower machines are assigned
less work. Simulations based on a Facebook workload
demonstrate that by mitigating stragglers, tiny tasks
can improve response times by as much as a factor of 5.2.
\eat{
Prior work has shown that tasks runtimes exhibit a long
tailed distribution, and are highly variable. This variance can be caused by
a number of factors, including slow machines, congested networks, a single task
processing larger amount of data, or a combination of the above.
Many mechanisms have been suggested for mitigating
the effects of this variability, generally either by avoiding causes of these
long task runtimes, or by speculatively launching additional tasks in response to slow tasks.
By providing the scheduler with fine grained control over job execution, tiny
tasks makes such mitigation easier, allowing the scheduler to change the resources
allocated to a job in response to outliers.\\
}


Using smaller tasks offers performance improvements even in
today's frameworks.  However, we propose task durations of at most
hundreds of milliseconds across all jobs, which cannot be supported without addressing
numerous challenges. First, small tasks require a highly scalable scheduler
that can make frequent scheduling decisions. Second,
task launch overheads must be small enough so as not to counteract the
benefits from using small tasks.
Third, tiny tasks must operate on correspondingly tiny amounts
of data, which requires a file system that can handle a large number of
small file blocks. Finally, tiny tasks require modifications to current programming
models to allow \emph{all} jobs to be split into tiny tasks. We propose an
architecture that addresses these challenges using a distributed scheduler, and an execution model that gives the execution framework control
over I/O. Our proposed design supports
50 microsecond task launches, and allows most applications to be
expressed in terms of a set of tiny tasks.

We begin by quantifying the benefits of tiny tasks in~\S\ref{sec:benefits}.
We present a preliminary system design that addresses the challenges of
supporting tiny tasks in~\S\ref{sec:architecture},
and explore design alternatives and related work in~\S\ref{sec:alternate}.
\eat{
Existing data-parallel systems have engineering limitations in their distributed
file systems and cluster schedulers that prevent short task runtimes. For example, in
large Hadoop clusters, a larger block size is advised to avoid overflowing the name node.
Hadoop also piggybacks the heartbeat messages to send scheduling decisions, which
results in high scheduling latency.
Current frameworks need to be re-architected to enable tasks to be broken into even smaller
units.
Recent work on distributed filesystems\cite{nightingale2012flat} and cluster
schedulers\cite{ousterhoutbatch} present the first steps towards
building a cluster framework that allows for tiny tasks. While these new filesystems
and schedulers address the scalability problems, many challenges remain. In particular,
efficient use of tiny tasks requires that the overhead for launching a task is small. Current
frameworks take on the order of several hundred milliseconds to a second to launch a task, negating
many of the gains provided by a system with sub-second task lengths. Similarly, any system
supporting tiny tasks must provide additional architectural support for more easily dividing tasks.
}

