\section{Alternate Designs and Related Work}
\label{sec:alternate}

Tiny tasks solve two major problems in data centers: outliers, and sharing
a cluster between batch and interactive or user-facing jobs. A variety of
approaches solve one of the two problems in isolation; e.g., skew handling
techniques mitigate outliers, and process migration allows improved
sharing between long and short jobs.  Unlike these approaches, tiny tasks
provides a simple design paradigm that solves both problems.

\subsection{Preemption and Process Migration}
%\subsection{Alternate Design Schemes}

Our choice of a cooperative multi-tasking scheme is in contrast to
preemption based schemes commonly used in operating systems. 
The benefits of
preemption are well studied in operating
systems literature; for instance~\cite{sherman1972trace} shows the benefits
of short scheduling quanta. Work in distributed
operating systems~\cite{douglis1991transparent,milojivcic2000process,rozier1991overview} and virtual machines~\cite{tanenbaum1990experiences}
has applied preemption in a distributed context by exploring migrating
processes between machines.
Compared to tiny tasks, one advance of preemption is that scheduling quanta
can be tightly controlled, since the framework (or operating system) controls
when the task is preempted. However, preemption has other disadvantages:

%However achieveing low overhead task-switching is more expensive in the distributed setting.
\vspace{4pt}\noindent\textbf{Cost of task-switching:}
Work on process
migration~\cite{douglis1991transparent,milojivcic2000process} and virtual
machine migration~\cite{clark2005live} has shown mechanisms to transparently
move tasks across machines. Such methods, however, involve a high overhead, as
migrating a task involves transferring both task context, a task's intermediate
data, and its inputs. For data parallel applications, input data, and intermediate
data can be several gigabytes, incurring very high overheads.

%Cooperative multitasking, by contrast, eliminates the need to migrate such data. In
%addition, we envision moving shared state into a framework-maintained scratch space.
%By explicitly differentiating such state, we envision that it can be more easily migrated.

\vspace{4pt}\noindent\textbf{Fault tolerance:}
In a data center setting, tiny tasks are better suited for
fault tolerance when compared to task preemption. Since each tiny task is a
deterministic unit of work, tasks can be executed in parallel during recovery.
In contrast, using preemption one would need to maintain redundant checkpoints
and fault recovery cannot be executed in parallel.

In spite of these challenges, recent work proposed Amoeba, a system that
uses preemption
in the context of MapReduce-like cluster computing frameworks~\cite{ananthanarayanan2012true}. Amoeba
identifies safe-points where a task can be paused and restarted elsewhere
without wasted work. The main drawback of Amoeba is that it does not provide a mechanism for determining
such safe-points, which is difficult for general tasks (even tasks that
use the MapReduce programming model).
The Amoeba authors choose preemptability rather than small tasks for two
reasons. First, they cite high task launch overheads in systems like
Hadoop; as described in~\S\ref{sec:prog}, these overheads are not fundamental and
can be solved with improved engineering. Second, they note that creating
\emph{uniformly} sized small tasks is difficult. Tasks need not be uniformly
sized for the benefits of tiny tasks to hold; rather, tasks must be
orders of magnitude smaller than today's tasks.

\subsection{Static Partitioning}
Omega, Google's newest cluster scheduler~\cite{melnik2010dremel},
was designed to share cluster
resources between batch and interactive workloads. However, Omega achieves
this by
statically partitioning cluster resources.
Interactive services like Dremel~\cite{melnik2010dremel} spin up long-running
agents that serve incoming queries, rather than scheduling new resources for
each request.  Static partitioning limits utilization because each service
must be provisioned to handle peak load, and one service's extra capacity
cannot easily be reallocated to another service.

\subsection{Skew-Handling}
A separate line of research has focused on skew-mitigation to improve job
performance in data centers. Examples of such work include
Mantri~\cite{ananthanarayanan2010reining}, SkewTune~\cite{kwon2012skewtune},
Scarlett~\cite{ananthanarayanan2011scarlett}, and work on task
speculation~\cite{zaharia2008improving}. Mantri and Scarlett attempt to
mitigate task runtime skew by modeling the causes for skew and accounting for
these causes when scheduling tasks. In particular, Mantri performs resource aware scheduling to decrease the
probability of observing task skews, while Scarlett replicates storage blocks
based on their probability to decrease the wait time for a popular block. While
both of these systems moderately reduce task skew, they rely on a fragile set of
signals, and do not work in all cases.
%Using tiny tasks naturally overcomes data
%skew among reduce tasks as fine-grained hash partitioning ensures that the data is
%more evenly spread across tasks. As shown in
%Section~\ref{sec:benefits}, using tiny tasks also allows work to be balanced across
%different machines thereby overcoming skew due to slow machines.
Furthermore, existing skew mitigation techniques trade-off cluster resources to
gain more predictable task runtimes. This limits the applicability of these
techniques under situations of high load, where such guarantees might be most
important.

